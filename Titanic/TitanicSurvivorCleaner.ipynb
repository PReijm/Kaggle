{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python379jvsc74a57bd08e451edc9633588bb69a413542b83b6526d3d4cf2c31aa0035645349f27e347e",
   "display_name": "Python 3.7.9 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Titanic - Machine Learning from Disaster\n",
    "\n",
    "part 1 - data cleaning\n",
    "\n",
    "https://dataisutopia.com/blog/preprocessing-titanic-dataset/\n",
    "\n",
    "https://medium.com/analytics-vidhya/exploratory-data-analysis-of-titanic-survival-problem-e3af0fb1f276\n",
    "\n",
    "https://towardsdatascience.com/machine-learning-with-the-titanic-dataset-7f6909e58280"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#load packages\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data\n",
    "df_train = pd.read_csv('Data/train.csv')\n",
    "df_test = pd.read_csv('Data/test.csv')"
   ]
  },
  {
   "source": [
    "## Data inspection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train data contains \" + str(len(df_train)) + \" rows and \" + str(len(df_train.columns)) + \" columns\")\n",
    "print(\"Test data contains \" + str(len(df_test)) + \" rows and \" + str(len(df_test.columns)) + \" columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMissing values of train dataset:\\n\") \n",
    "display(df_train.isnull().sum()) \n",
    "print(\"\\nMissing values of test dataset:\\n\") \n",
    "display(df_test.isnull().sum()) "
   ]
  },
  {
   "source": [
    "### Some additional info"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nGeneral information of train data:\\n\") \n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDescriptive statistics of numeric columns in train data:\\n\") \n",
    "df_train.describe().round(2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualise the missing values\n",
    "sns.heatmap(df_train.isnull(), cmap='viridis', cbar=False)"
   ]
  },
  {
   "source": [
    "## Data cleaning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a complete dataset\n",
    "df_all = pd.concat([df_train, df_test], sort=True).reset_index(drop=True)"
   ]
  },
  {
   "source": [
    "### Inspect missing values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sumarize missing ages\n",
    "print('Number of passenger without age: ' + str(df_all.Age.isnull().sum()))\n",
    "print('This is ' + str(round(df_all.Age.isnull().sum()/len(df_all)*100,0)) + '% of the total passengers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check median age per category\n",
    "print(\"Median per Class and Sex:\")\n",
    "display(df_all.groupby(['Pclass', 'Sex'])['Age'].median())\n",
    "\n",
    "#check if there are enough samples\n",
    "print(\"Counts per Class and Sex:\")\n",
    "display(df_all.groupby(['Pclass', 'Sex'])['Age'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find row with missing Fare is used to search for similar passengers\n",
    "df_all.loc[df_all['Fare'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these passenger were together and Embarked in Southampton (source https://www.encyclopedia-titanica.org/)\n",
    "df_all.loc[df_all['Embarked'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count missing values in Cabin column\n",
    "print('There are ' + str(df_all['Cabin'].isnull().sum()) + ' cabin values missing!\\n')\n",
    "\n",
    "#too much values are missing, check for additional features\n",
    "print('There are ' + str(len(df_all['Cabin'].unique())) + ' unique cabin values:')\n",
    "print(str(df_all['Cabin'].unique()))"
   ]
  },
  {
   "source": [
    "### Create a cleaned dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(df):\n",
    "    dfc = df.copy()\n",
    "\n",
    "    #drop PassengerId column because it is useless\n",
    "    dfc.drop('PassengerId', axis=1, inplace=True)\n",
    "\n",
    "    #fill gaps in Age column with random values around mean age\n",
    "    # age_mean = dfc['Age'].mean()\n",
    "    # age_std = dfc['Age'].std()\n",
    "\n",
    "    # def fill_age(col):\n",
    "    #     if np.isnan(col):\n",
    "    #         return np.random.randint(age_mean-age_std, age_mean+age_std)\n",
    "    #     return(col)\n",
    "    \n",
    "    # dfc['Age'] = dfc['Age'].apply(fill_age).astype(int)\n",
    "\n",
    "    #a better method is to fill gaps with median per group of class and sex\n",
    "    dfc['Age'] = dfc.groupby(['Pclass', 'Sex'])['Age'].apply(lambda x: x.fillna(x.median()))\n",
    "    \n",
    "    #fill few missing values in Embarked with most frequent value (Southampton)\n",
    "    dfc['Embarked'].fillna('S', inplace=True)\n",
    "\n",
    "    #fill missing Fare value of Mr. Thomas with median of similar passengers\n",
    "    SimPasFare = dfc.loc[(dfc['Pclass'] == 3) & (dfc['SibSp'] == 0) & (dfc['Embarked'] == 'S')]['Fare'].median()\n",
    "    dfc.loc[dfc['Fare'].isnull(), 'Fare'] = SimPasFare\n",
    "\n",
    "    #round fare and age column\n",
    "    dfc['Age'] = dfc['Age'].round(0).astype(int)\n",
    "    dfc['Fare'] = dfc['Fare'].round(0).astype(int)\n",
    "\n",
    "    return dfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_clean = cleaning(df_all)"
   ]
  },
  {
   "source": [
    "## Feature engineering"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make copy of cleaned dataset\n",
    "df_all_clean_feat = df_all_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#add children as addition to male/female\n",
    "def children(passenger):\n",
    "    age, sex = passenger\n",
    "\n",
    "    if age <16:\n",
    "        return 'child'\n",
    "    else:\n",
    "        return sex\n",
    "\n",
    "df_all_clean_feat['Person'] = df_all_clean_feat[['Age','Sex']].apply(children, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add column about if passenger had a cabin\n",
    "def missing_cabin(col):\n",
    "\n",
    "    if isinstance(col, type(np.nan)):\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "df_all_clean_feat['HasCabin'] = df_all_clean_feat['Cabin'].apply(missing_cabin)"
   ]
  },
  {
   "source": [
    "def family (df):\n",
    "\n",
    "    df.is_copy = False\n",
    "\n",
    "    #add column about traveling alone\n",
    "    df['IsAlone'] = df['Parch'] + df['SibSp']\n",
    "    df['IsAlone'] = np.where(df['IsAlone']>0, 0, 1)\n",
    "\n",
    "    #add column about family size\n",
    "    df['FamilySize'] = df['Parch'] + df['SibSp'] + 1\n",
    "\n",
    "    #bin the family size\n",
    "    df['FamilySizeBin'] = df['FamilySize'].apply(lambda x: 1 if x==1 else (2 if x==2 else (3 if (x==3) | (x==4) else (4 if x >= 5 else 0))))\n",
    "\n",
    "    return df\n",
    "\n",
    "df_all_clean_feat = family(df_all_clean_feat)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are some people who paid a lot of money\n",
    "df_all_clean_feat.boxplot(column=['Fare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide the fare in 4 groups to deal with the outliers\n",
    "def group_fare (df, colname):\n",
    "    return pd.qcut(df[colname], 5, labels = [1, 2, 3, 4, 5]).astype(int)\n",
    "\n",
    "df_all_clean_feat['CategoricalFare'] = group_fare(df_all_clean_feat, 'Fare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of passenger per group are more or less equal (qcut method)\n",
    "df_all_clean_feat['CategoricalFare'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there were some old people on the ship \n",
    "df_all_clean_feat.boxplot(column=['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide age in 5 groups to deal with the outliers\n",
    "df_all_clean_feat['CategoricalAge'] = pd.cut(df_all_clean_feat['Age'].astype(int), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of passenger per group are different (cut method)\n",
    "df_all_clean_feat['CategoricalAge'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add column with ticket frequency\n",
    "df_all_clean_feat['TicketFrequency'] = df_all_clean_feat.groupby('Ticket')['Ticket'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add columns with deck information\n",
    "df_all_clean_feat['Deck'] = df_all_clean_feat['Cabin'].apply(lambda x: x[0] if pd.notnull(x) else 'M')\n",
    "\n",
    "#only one passenger on deck T (boat deck), so replace with deck A\n",
    "idx = df_all_clean_feat[df_all_clean_feat['Deck'] == 'T'].index\n",
    "df_all_clean_feat.loc[idx, 'Deck'] = 'A'\n",
    "\n",
    "#group several deck according to classes\n",
    "df_all_clean_feat['DeckGroup'] = df_all_clean_feat['Deck']\n",
    "df_all_clean_feat['DeckGroup'] = df_all_clean_feat['DeckGroup'].replace(['A', 'B', 'C'], 'ABC')\n",
    "df_all_clean_feat['DeckGroup'] = df_all_clean_feat['DeckGroup'].replace(['D', 'E'], 'DE')\n",
    "df_all_clean_feat['DeckGroup'] = df_all_clean_feat['DeckGroup'].replace(['F', 'G'], 'FG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create column with title of the passenger\n",
    "def title (df, colname):\n",
    "\n",
    "    def find_title (x):\n",
    "        title_search = re.search('([A-Za-z]+)\\.', x)\n",
    "\n",
    "        if title_search:\n",
    "            title = title_search.group(1)\n",
    "\n",
    "            if title in ['Mlle', 'Ms', 'Miss']:\n",
    "                return 'Miss'\n",
    "            elif title in ['Mme', 'Mrs']:\n",
    "                return 'Mrs'\n",
    "            elif title in ['Mr', 'Master']:\n",
    "                return 'Mr'\n",
    "            else:\n",
    "                return 'Rare'\n",
    "\n",
    "        return \"\"\n",
    "\n",
    "    return_title = df[colname].apply(find_title)\n",
    "\n",
    "    return return_title\n",
    "\n",
    "df_all_clean_feat['Title'] = title(df_all_clean_feat, 'Name')         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add column with info about marriage\n",
    "df_all_clean_feat['IsMarried'] = 0\n",
    "df_all_clean_feat['IsMarried'].loc[df_all_clean_feat['Title'] == 'Mrs'] = 1"
   ]
  },
  {
   "source": [
    "## Data encoding"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make copy of engineered dataset\n",
    "df_all_clean_feat_enc = df_all_clean_feat.copy()\n",
    "\n",
    "#list of all columns\n",
    "df_all_clean_feat_enc.columns"
   ]
  },
  {
   "source": [
    "### One-Hot Encoding"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodingOne (df):\n",
    "    \n",
    "    #select cols to do the encoding\n",
    "    cols = ['Person', 'Embarked', 'Title', 'DeckGroup', 'CategoricalAge', 'CategoricalFare', 'FamilySizeBin', 'Pclass']\n",
    "\n",
    "    #keep the orginal columns\n",
    "    df_orginal = df[cols]\n",
    "\n",
    "    #do the encoding\n",
    "    df_dummies = pd.get_dummies(df, columns=cols)\n",
    "\n",
    "    #append the orginal columns\n",
    "    df = pd.concat([df_dummies, df_orginal], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "df_all_clean_feat_enc = encodingOne(df_all_clean_feat_enc)"
   ]
  },
  {
   "source": [
    "### Integer Encoding"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_list = ['Embarked', 'Person', 'Title', 'Sex', 'Deck', 'DeckGroup', 'CategoricalAge']\n",
    "\n",
    "for feat in feat_list:\n",
    "    df_all_clean_feat_enc[feat] = LabelEncoder().fit_transform(df_all_clean_feat_enc[feat])"
   ]
  },
  {
   "source": [
    "## Final data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select only columns needed\n",
    "drop_list = ['Cabin', 'Ticket', 'Name']\n",
    "df_all_final = df_all_clean_feat_enc.drop(drop_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#double check for missing values\n",
    "df_all_final.loc[:, df_all_final.columns != 'Survived'].isnull().to_numpy().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_final.to_csv('Data/clean.csv', index=False)"
   ]
  }
 ]
}